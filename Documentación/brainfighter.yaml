behaviors:
  Brainfighter:
    trainer_type: ppo
    summary_freq: 5000
    time_horizon: 64
    max_steps: 1000000
    keep_checkpoints: 4
    even_checkpoints: false
    checkpoint_interval: 250000
    threaded: false
    hyperparameters:
      learning_rate: 0.0001
      batch_size: 32
      buffer_size: 10240
      learning_rate_schedule: linear
      beta: 0.005
      epsilon: 0.2
      beta_schedule: constant
      epsilon_schedule: linear
      lambd: 0.98
      num_epoch: 3
      shared_critic: False
    network_settings:
      hidden_units: 512
      num_layers: 8
      normalize: false
      conditioning_type: none
    reward_signals:
      extrinsic:
        strength: 1.0
        gamma: 0.9
      # curiosity:
      #   strength: 0.0005
      #   gamma: 0.99
      #   learning_rate: 0.0003
      #   network_settings:
      #     hidden_units: 64
      #     num_layers: 4
    self_play:
      save_steps: 20000
      team_change: 100000
      swap_steps: 10000
      playing_against_latest_model_ratio: 0.5
      window: 10
